# This file is used to set up the parameters for data loading, logging, preprocessing, etc.
# Add this at the very top of your existing config.yaml
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}


defaults:
  - dataset: local
  - _self_

main:
  # list or string, depending on how main.py expects it
  steps: "all"      # or specific steps like "features,preprocess,models"
  WANDB_PROJECT: mlops-project # whatever you call the project in Weights & Biases
  WANDB_ENTITY: aviv275-ie-university          # optional; omit if you use the default entity


data_source:
  raw_path_futures: "https://fapi.binance.com/fapi/v1/fundingRate"
  raw_path_spot: "https://api.binance.com/api/v3/klines"
  processed_path: "./data/processed/futures_data_processed_.csv" # Path to save processed data
  # Path to the raw data file after fetching
  raw_path: data/raw/raw_data.csv

logging:
  level: "INFO" # Logging level: DEBUG (verbose), INFO (default), WARNING, ERROR, CRITICAL
  log_file: "./logs/main.log" # File path for log output
  format: "%(asctime)s - %(levelname)s - %(name)s - %(message)s" # Log message format
  datefmt: "%Y-%m-%d %H:%M:%S" # Date format for logs

data_load:
  column_names:
    - timestamp
    - open
    - high
    - low
    - close
    - volume
    - close_time
    - quote_volume
    - trades
    - taker_base
    - taker_quote
    - ignore
  # Add these keys for conditional logging in W&B
  log_sample_rows: true
  log_summary_stats: true

symbols:
  - ETHUSDT
  - BNBUSDT
  - XRPUSDT
  - ADAUSDT
  - SOLUSDT
  - BTCUSDT

features:
  - ETHUSDT_price
  - BNBUSDT_price
  - XRPUSDT_price
  - ADAUSDT_price
  - SOLUSDT_price
  - BTCUSDT_funding_rate
  - ETHUSDT_funding_rate
  - BNBUSDT_funding_rate
  - XRPUSDT_funding_rate
  - ADAUSDT_funding_rate
  - SOLUSDT_funding_rate

target: BTCUSDT_price

data_validation:
  enabled: true
  missing_values_strategy: impute
  report_path: logs/validation_report.json
  schema:
    columns:
      - name: "ETHUSDT_price"
        dtype: "float64"
        required: true
        min: 1
        max: 5000
        on_error: warn

      - name: "BNBUSDT_price"
        dtype: "float64"
        required: true
        min: 1
        max: 5000
        on_error: warn

      - name: "XRPUSDT_price"
        dtype: "float64"
        required: true
        min: 0
        max: 10
        on_error: warn

      - name: "ADAUSDT_price"
        dtype: "float64"
        required: true
        min: 0
        max: 10
        on_error: warn

      - name: "SOLUSDT_price"
        dtype: "float64"
        required: true
        min: 1
        max: 5000
        on_error: warn

      - name: "ETHUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for ETHUSDT"
      - name: "BNBUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for BNBUSDT"
      - name: "XRPUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for XRPUSDT"
      - name: "ADAUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for ADAUSDT"
      - name: "SOLUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for SOLUSDT"
        
      - name: "BTCUSDT_funding_rate"
        dtype: "float64"
        description: "Funding rate for BTCUSDT"
      - name: "BTCUSDT_price"
        dtype: "float64"
        description: "Price for BTCUSDT (Target Variable)"
      - name: "timestamp"
        dtype: "object" # Pandas reads datetime-like strings as object
        description: "Timestamp of the data point"

    # Strategy for handling missing values: 'drop' or 'impute'
    missing_values_strategy: "impute"
    # Action on validation error: 'raise' or 'warn'

data_split:
    test_size: 0.2
    valid_size: 0.2
    random_state: 42
    
preprocessing:
  
  scaling:
    method: standard
    columns: [] # or list of columns

  sampling:
    method: smote
    params:
      sampling_strategy: auto
      random_state: 42
    threshold_ratio: 1.5

feature_engineering:
  feature_selection:
    method: random_forest
    params:
      n_estimators: 20
      random_state: 42
    top_n: 8

model:
  active: linear_regression # Options: logistic_regression, linear_regression

  linear_regression:
    save_path: models/linear_regression.pkl
    params:
      fit_intercept: true
      copy_X: true
      positive: false

  logistic_regression:
    save_path: models/logistic_regression.pkl
    params:
      penalty: "l2"
      solver: "lbfgs"
      random_state: 42
      max_iter: 200

metrics:
  linear_regression:
    display:
      - RMSE
    report:
      - RMSE

  logistic_regression:
    display:
      - ROC AUC
      - Confusion Matrix

    report:
      - Accuracy
      - F1 Score
      - ROC AUC
      - Confusion Matrix

artifacts:
  metrics_path: models/metrics.json
  preprocessing_pipeline: models/preprocessing_pipeline.pkl
  splits_dir: data/splits
  processed_dir: data/processed

inference:
  input_csv: data/raw/test.csv
  output_csv: data/processed/predictions.csv